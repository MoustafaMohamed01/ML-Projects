{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b6922-798c-4e6f-a84d-3076b7c137c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff4c75-6e5c-4b15-acea-712840792cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import quandl\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d599894-5ebf-44ef-90b2-932cfaeb5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('NSE-TATAGLOBAL11.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'NSE-TATAGLOBAL11.csv' not found. Please ensure the file is in the same directory.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa587b-6a88-474b-a801-2f732844afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Open - Close'] = df['Open'] - df['Close']\n",
    "df['High - Low'] = df['High'] - df['Low']\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b35c56-4f8e-4948-8444-579df466ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Open - Close', 'High - Low']].iloc[:-1]\n",
    "y = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c41b2-694f-4599-a109-36b5f7b05a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae65cdf-fcbb-4d2b-a1df-57d243210658",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38793594-cf50-4bdd-92f1-ce036946a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTraining data shape: {X_train.shape}, Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad7b3a-d0d6-404e-87ba-7ec0c35d5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {'C': [0.01, 0.1, 1, 10]}\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [5, 7, 9, 11]}\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        'model': DecisionTreeClassifier(random_state=44),\n",
    "        'params': {'max_depth': [3, 5, 7]}\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(random_state=44),\n",
    "        'params': {'n_estimators': [50, 100], 'max_depth': [5, 10]}\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        'model': GradientBoostingClassifier(random_state=44),\n",
    "        'params': {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(random_state=44),\n",
    "        'params': {'C': [0.1, 1], 'kernel': ['linear', 'rbf']}\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=44),\n",
    "        'params': {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80586e-e3ff-4222-b59d-b10b96211d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_model_name = \"\"\n",
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f79a0-f222-49e9-a337-974c0201f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, config in models.items():\n",
    "    print(colored(f\"\\nTraining Model: {name}\", \"cyan\", attrs=[\"bold\"]))\n",
    "    print(colored(\"═════════════════════════════════════════════════\", \"blue\"))\n",
    "\n",
    "    grid_search = GridSearchCV(config['model'], config['params'], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, grid_search.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, grid_search.predict(X_test))\n",
    "\n",
    "    model_results[name] = {\n",
    "        'best_estimator': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"Best Parameters   : {grid_search.best_params_}\")\n",
    "    print(f\"Train Accuracy    : {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy     : {test_accuracy:.4f}\")\n",
    "    \n",
    "    print(colored(\"═════════════════════════════════════════════════\", \"blue\"))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c8eef-c3f8-4ddd-9651-789cab1667ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for name, result in model_results.items():\n",
    "    summary_data.append({\n",
    "        'Model': name,\n",
    "        'Best Parameters': result['best_params'],\n",
    "        'Train Accuracy': round(result['train_accuracy'], 4),\n",
    "        'Test Accuracy': round(result['test_accuracy'], 4)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972369a-e0af-4557-bf22-860b445b8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values(by='Test Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c9213-a436-48a0-8e35-17f199479a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Comparison Summary ---\")\n",
    "print(summary_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e003fef-7eb4-41ae-bb53-7705c732683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model:\n",
    "    print(f\"The best model is: {best_model_name}\")\n",
    "    print(f\"With Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    model_filename = 'best_stock_prediction_model.pkl'\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    print(f\"Best model saved as: {model_filename}\")\n",
    "else:\n",
    "    print(\"No best model found. Something might have gone wrong with training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75e506-9a53-42c8-970b-2ae842007e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "sorted_results = dict(sorted(\n",
    "    {name: res['test_accuracy'] for name, res in model_results.items()}.items(),\n",
    "    key=lambda item: item[1], reverse=True\n",
    "))\n",
    "model_names = list(sorted_results.keys())\n",
    "accuracies = list(sorted_results.values())\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "palette = sns.color_palette(\"Spectral\", len(model_names))\n",
    "bars = sns.barplot(x=model_names, y=accuracies, palette=palette)\n",
    "\n",
    "for i, bar in enumerate(bars.patches):\n",
    "    height = bar.get_height()\n",
    "    bars.annotate(f'{height:.2%}', (bar.get_x() + bar.get_width() / 2, height),\n",
    "                  ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.title('Comparison of ML Model Test Accuracies', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Model', fontsize=13)\n",
    "plt.ylabel('Test Accuracy', fontsize=13)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=45, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/comparison-of-ml-models-acc.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ade93-5d94-4a6e-ac2b-0aa761cbd788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
